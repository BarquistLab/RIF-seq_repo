---
title: "Statistical model for scRNA-seq"
author: "Laura Jenniches"
date: "10/8/2020"
output:
  pdf_document: default
  html_document: default
---

#
```{r}
knitr::opts_chunk$set(fig.path=paste0(getwd(),"/../figures/"), warning=F,
                      message=F, echo=F, dev="cairo_pdf")
```

load R packages

```{r}
library(ggplot2)
library(viridis)

library(tidyverse)
library(data.table)

library(cmdstanr)
library(bayesplot)

source("../R/convert_cmdstan.R")
source("../R/utils.R")
source("../R/norm_fun.R")

theme_set(theme_bw(base_size = 10))
```

set and create data and results directories, load gene meta data

```{r}
# set result directory for plots etc.
data_dir <- paste0(getwd(), "/../data/")
res_dir <- paste0(getwd(), "/../figures/")
if(!dir.exists(res_dir)) dir.create(res_dir)
cb_palette <- c(viridis(9)[1:8], "orange")

# load reads
meta_data <- read.table(paste0(getwd(), "/../annotations/Salmonella_meta.csv"), quote="\"", stringsAsFactors=F, header=T, sep="\t")
rownames(meta_data) <- meta_data$locus_tag
```

```{r}
read_counts_in <- fread(paste0(data_dir, "proQ_RIF-seq_1-50.csv"), data.table=F)
colnames(read_counts_in)[1] <- "locus_tag"

# remove ProQ++ samples for example run
read_counts_in <- read_counts_in[,-grep("proQp", colnames(read_counts_in))]

# create long data.frame which has to correct format to export data for cmdstan and for downstream analysis of the modeling results
stan_df <- read_counts_in[grep("^[Sn]",read_counts_in$locus_tag),] %>% pivot_longer(!locus_tag, names_to="sample", values_to="raw")
sample_info <- strsplit(stan_df$sample, "_")
stan_df$locus_tag <- stan_df$locus_tag %>% factor(levels=read_counts_in$locus_tag)

# relevel stan_df$condition to the control condition/strain.
# Differences in decay rate will be given relative to the control.
stan_df$condition <- sample_info %>% sapply(function(x) x[1]) %>% factor  %>% relevel(ref="WT")
stan_df$time <- sample_info %>% sapply(function(x) sub("min", "", x[2])) %>% as.numeric()
stan_df$replicate <- sample_info %>% sapply(function(x) sub("R", "", x[3])) %>% as.numeric()

rownames(read_counts_in) <- read_counts_in$locus_tag
read_counts_in <- read_counts_in[,-grep("locus_tag", colnames(read_counts_in))]

stan_df$sample <- factor(stan_df$sample, levels=colnames(read_counts_in))
```

TMM Normalization with ERCC spike-ins

```{r}
proQ_ercc <- read_counts_in[grep("ERCC",rownames(read_counts_in)),]
# remove ERCC spike-ins with zero counts if any
remove_ercc <- which(apply(proQ_ercc, 1, prod)==0)
if(length(remove_ercc)!=0) proQ_ercc <- proQ_ercc[-remove_ercc,]
proQ_reads <- read_counts_in[grep("^[Sn]",rownames(read_counts_in)),]
nf_proQ <- get_norm_facs(proQ_reads, proQ_ercc, count_min=0, sample_min=0)
```

Add meta data and sample parameters to long data.frame

```{r}
# add common ID, library size and normalization factor to long data.frame
stan_df$com_id <- meta_data$com_id[match(stan_df$locus_tag, meta_data$locus_tag)]
stan_df$N_lib <- colSums(proQ_reads)[match(stan_df$sample, colnames(proQ_reads))]
stan_df$n_f <- nf_proQ[match(stan_df$sample, colnames(proQ_reads))]
# calculate cpm and logcpm values
stan_df <- stan_df %>% mutate(cpm=(raw+0.5)*1e6/(N_lib*n_f+1), logcpm=log((raw+0.5)*1e6/(N_lib*n_f+1)))

# Perform center-mean normalization. This is only required for downstream analysis, the Stan models work with raw counts and the center mean normalization is performed within the Stan models
stan_df_t0 <- subset(stan_df, time==0) %>% group_by(locus_tag, condition) %>% summarise(logcpm0=logcpm %>% mean)
stan_df$logcpm0 <- stan_df_t0$logcpm0[match(paste0(stan_df$locus_tag, stan_df$condition), paste0(stan_df_t0$locus_tag, stan_df_t0$condition))]
stan_df <- stan_df %>% mutate(logrel=logcpm - logcpm0)
stan_df_tmp <- stan_df %>% group_by(locus_tag, condition, time) %>% summarise(logrel_avg=logrel %>% mean)
stan_df$logrel_avg <- stan_df_tmp$logrel_avg[match(paste0(stan_df$locus_tag, stan_df$condition, stan_df$time), paste0(stan_df_tmp$locus_tag, stan_df_tmp$condition, stan_df_tmp$time))]
stan_df_tmp <- stan_df %>% group_by(condition, time, replicate) %>% summarise(lognf2=mean(logrel-logrel_avg))
stan_df$logrel2 <- stan_df$logrel - stan_df_tmp$lognf2[match(paste0(stan_df$time, stan_df$condition, stan_df$replicate), paste0(stan_df_tmp$time, stan_df$condition, stan_df_tmp$replicate))]
```

Verify that the center-mean normalization worked. Residuals of all replicates should be centered around 0.

```{r}
stan_df %>% subset(time==3) %>% ggplot(aes(logrel2-logrel_avg, col=(replicate %>% factor))) +
  geom_density()
```

Variables for Stan

```{r}
# Define iterators required by the Stan models
# condition, sample and locus_tag are expected to be factors, replicate and time numeric.
it_c = stan_df$condition %>% as.numeric
it_b = stan_df$replicate
it_s = stan_df$sample %>% as.numeric
it_g = stan_df$locus_tag %>% as.numeric
it_t = stan_df$time %>% factor(levels=c("0", "3", "6", "12", "24")) %>% as.numeric

# number of genetic features
N_g = unique(stan_df$locus_tag) %>% length
# combined iterators
it_gc = (it_c - 1)*N_g + it_g
N_t = unique(stan_df$time) %>% length

data_list <- list(
  # raw read counts, will be converted to log-counts in the Stan model
  raw = stan_df$raw,
  t = stan_df$time,
  it_g = it_g,
  it_c = it_c,
  it_t = it_t,
  it_b = it_b,
  it_s = it_s,
  
  it_gc = it_gc,
  it_gct = (it_gc - 1)*N_t + it_t,
  it_gt = (it_g - 1)*N_t + it_t,
  
  # number of conditions/strains, including the reference condition/strain
  N_con = max(it_c),
  # number of samples/sequencing libraries
  N_s = max(it_s),
  # number of replicates per condition, same order as in it_c
  N_b = stan_df %>% group_by(condition) %>% summarize(N_b=unique(it_b) %>% length) %>% pull(N_b),
  N_t = N_t,
  N_g = N_g,
  # total number of data points
  N_tot = nrow(stan_df),
  
  # TMM normalization factors and library sizes, same order as in it_s
  n_f = nf_proQ,
  N_lib = colSums(proQ_reads),

  # Remove batch effects by using center mean normalization (yes=1, no=0)
  batch_effects = 1,
  # Choose model:
  # 1: LNM
  # 2: LM
  # 3: PLM
  model_id = 1
)
```

Run cmdstan and save fit results. Alternatively, data can be exported with stan_rdump

```{r}
stan_file <- paste0(getwd(), "/../stan_models/LNM-1.0.stan")
mod <- cmdstan_model(stan_file, pedantic=F)

json_file <- tempfile(fileext = ".json")
write_stan_json(data_list, json_file)

# fit model with cmdstan
fit0 <- mod$sample(data = json_file, chains = 2, adapt_delta = 0.95, parallel_chains = 2, iter_warmup = 500, iter_sampling = 500, max_treedepth = 12)

# save fitted model
fit0$save_object(file = paste0(res_dir, "fit_LNM.RDS"))
rm(fit0)
```

Bayesian diagnostics

```{r}
# load fitted model
fit0 <- readRDS(paste0(res_dir, "fit_LNM.RDS"))

# use the bayesplot packages to check for divergent transitions and correlations between parameters
# Pairs plots
x <- fit0$draws()
i <- "LNM_1"
p <- mcmc_pairs(x, pars = paste0("delta_beta[", 1:10, "]"),
           off_diag_args = list(size = 1, alpha = 0.5), np=nuts_params(fit0))
print(p)
cairo_pdf(paste(res_dir, "pairs_", i, ".pdf", sep=""), width = 20, height = 20)
print(p)
dev.off()
png(paste(res_dir, "pairs_", i, ".png", sep=""), width = 1500, height = 1500)
print(p)
dev.off()
i <- "LNM_2"
p <- mcmc_pairs(x, pars = c("mu_beta", "beta_WT[1]", "delta_beta[1]", "sigma_g[1,1]"),
           off_diag_args = list(size = 1, alpha = 0.5), np=nuts_params(fit0))
print(p)
cairo_pdf(paste(res_dir, "pairs_", i, ".pdf", sep=""), width = 10, height = 6)
print(p)
dev.off()
png(paste(res_dir, "pairs_", i, ".png", sep=""), width = 800, height = 500)
print(p)
dev.off()

# trace plots to check whether the model fit has converged and whether all chains agree
p <- mcmc_trace(x, pars = c("mu_beta", "beta_WT[1]", "delta_beta[1]", "sigma_g[1,1]"),
           off_diag_args = list(size = 1, alpha = 0.5), np=nuts_params(fit0))
print(p)
cairo_pdf(paste(res_dir, "trace_", i, ".pdf", sep=""), width = 10, height = 6)
print(p)
dev.off()
png(paste(res_dir, "trace_", i, ".png", sep=""), width = 800, height = 500)
print(p)
dev.off()

i <- "LNM"
p <- mcmc_nuts_energy(nuts_params(fit0))
print(p)
cairo_pdf(paste(res_dir, "nuts_energy_", i, ".pdf", sep=""), width = 10, height = 6)
print(p)
dev.off()
png(paste(res_dir, "nuts_energy_", i, ".png", sep=""), width = 800, height = 500)
print(p)
dev.off()
```

Distribution of differences in decay rate

```{r}
delta_beta_draws <- fit0$draws(variables=c("delta_beta"), format="matrix")
delta_beta_proQ <- delta_beta_draws %>% apply(2, median)
beta_WT <- fit0$draws(variables=c("beta_WT"), format="matrix") %>% apply(2, median)
ggplot() +
  geom_histogram(aes(delta_beta_proQ/beta_WT))
diff <- which(delta_beta_proQ/beta_WT>0.05)
rownames(proQ_reads)[diff]
meta_data %>% subset(locus_tag %in% rownames(proQ_reads)[diff])
```

Extract parameters of interest and plot decay curves

```{r}
list_param <- fit0$draws(format="matrix") %>% as.data.frame() %>% extract_params()
list_param$locus_tag <- rownames(proQ_reads)
list_param$com_id <- meta_data$com_id[match(list_param$locus_tag, meta_data$locus_tag)]
```

```{r}
lab <- "ileS"
ig <- which(list_param$com_id==lab)
t <- (0:240)/10
fit_df <- data.frame(
  time=c(t,t),
  logrel=c(
    sapply(t, function(x) calc_mu(list_param$pib_WT[ig], list_param$beta_WT[ig], list_param$gamma[ig], x, "LNM")),
    sapply(t, function(x) calc_mu(list_param$pib_1[ig], list_param$beta_1[ig], list_param$gamma[ig], x, "LNM"))),
  condition=rep(c("WT", "dproQ"), each=length(t)))
subset(stan_df, com_id==lab) %>% ggplot(aes(x=time, y=logrel, col=condition)) +
  geom_point() +
  geom_line(aes(group=condition), data=fit_df) +
  scale_color_manual(name="", values=cb_palette_4[c(1,2)]) +
  theme(axis.line=element_line(linewidth=unit(0.1, "pt")),
        legend.position="top", legend.box="vertical",
        legend.margin=margin(t=-0.15, b=-0.15, unit="cm"),
        legend.key.width=unit(0.3,"cm"),legend.key.height=unit(0.3,"cm"),
        strip.background = element_rect(fill=NA, size=0.5), panel.spacing = unit(0, "lines"),
        panel.grid=element_blank(), axis.text=element_text(color = "black"))
```

```{r}
lab <- "yaaJ"
ig <- which(list_param$com_id==lab)
t <- (0:240)/10
fit_df <- data.frame(
  time=c(t,t),
  logrel=c(
    sapply(t, function(x) calc_mu(list_param$pib_WT[ig], list_param$beta_WT[ig], list_param$gamma[ig], x, "LNM")),
    sapply(t, function(x) calc_mu(list_param$pib_1[ig], list_param$beta_1[ig], list_param$gamma[ig], x, "LNM"))),
  condition=rep(c("WT", "dproQ"), each=length(t)))
subset(stan_df, com_id==lab) %>% ggplot(aes(x=time, y=logrel, col=condition)) +
  geom_point() +
  geom_line(aes(group=condition), data=fit_df) +
  scale_color_manual(name="", values=cb_palette_4[c(1,2)]) +
  theme(axis.line=element_line(linewidth=unit(0.1, "pt")),
        legend.position="top", legend.box="vertical",
        legend.margin=margin(t=-0.15, b=-0.15, unit="cm"),
        legend.key.width=unit(0.3,"cm"),legend.key.height=unit(0.3,"cm"),
        strip.background = element_rect(fill=NA, size=0.5), panel.spacing = unit(0, "lines"),
        panel.grid=element_blank(), axis.text=element_text(color = "black"))
```